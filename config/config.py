
"""
Configuration of training

@author: CHADLI KOUIDER
"""

# import the necessary packages
#import torch
#import os
# define the base path to the input dataset and then use it to derive
# the path to the input images and annotation CSV files
# BASE_PATH = "dataset"
# IMAGES_PATH = os.path.sep.join([BASE_PATH, "images"])
# ANNOTS_PATH = os.path.sep.join([BASE_PATH, "annotations"])
# define the path to the base output directory
# BASE_OUTPUT = "results"
# define the path to the output model, label encoder, plots output
# directory, and testing image paths
# MODEL_PATH = os.path.sep.join([BASE_OUTPUT, "detector.pth"])
# LE_PATH = os.path.sep.join([BASE_OUTPUT, "le.pickle"])
# PLOTS_PATH = os.path.sep.join([BASE_OUTPUT, "plots"])
# TEST_PATHS = os.path.sep.join([BASE_OUTPUT, "test_paths.txt"])
# determine the current device and based on that set the pin memory
# flag
# DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
# PIN_MEMORY = True if DEVICE == "cuda" else False
# specify ImageNet mean and standard deviation
MEAN = [0.485, 0.456, 0.406]
STD = [0.229, 0.224, 0.225]
# initialize our initial learning rate, number of epochs to train
# for, and the batch size
# INIT_LR = 1e-4
# NUM_EPOCHS = 20
BATCH_SIZE = 32
# specify the loss weights
# LABELS = 1.0
# BBOX = 1.0
import yaml

# Load the configuration file
with open("config.yaml", "r") as f:
    config = yaml.safe_load(f)

# Access the hyperparameters
learning_rate = config["learning_rate"]
batch_size = config["batch_size"]
num_epochs = config["num_epochs"]


