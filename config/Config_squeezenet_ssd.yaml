# Dataset information
dataset:
  train: D:\\master_project_codes\\heridal\\testImages
  val: D:\\master_project_codes\\heridal\\testImages
  num_classes: 1
  class_names: ['human']
  input_size: 256
# Model information
model:
  version: '1_1' # Available 1_1 or 1_0
  pretrained: True # True: load the pre-trained(backbone) model,
                    # False: create the (backbone) model from scratch
  type: 'float32' # Available options: float16, float32, float64
  ssd:
    feature_maps: [31,15, 8, 4, 2, 1]
    shrinkage: [9, 18, 32, 64, 128, 256] # the shrinkage factor
    min_sizes: [26, 67, 108, 149, 190, 231] # Minimum sizes of prior boxes
    max_sizes: [67, 108, 149, 190, 231, 256] # Maximum sizes of prior boxes
    aspect_ratios: [[2], [2, 3], [2, 3], [2, 3], [2], [2]] # Aspect ratios of prior boxes
    center_variance: 0.1
    size_variance: 0.2
    iou_thresh: 0.5 # IOU threshold for non-maximum suppression
    nms_thresh: 0.45 # NMS threshold for detection
    #=============================================================
    # Note to self: 
    # 1- pick m feature maps (chose m=6)
    # 2- shrinkage = round_up(size_of_image/feature_map)
    # 3- the scale of the default boxes is computed as follows: size_of_image * S_k
    #     where S_k = S_min +((S_max - S_min)/(m - 1))*(k-1)
    #     I set S_min = 0.1, S_max = 0.9
    #==============================================================

# Training information
train:
  batch_size: 32 # Batch size for training
  num_epochs: 50 # Number of epochs for training
  optimizer:
    type: SGD # Name of the optimizer
    lr: 0.001 # value of the learning rate
    momentum: 0.9
    weight_decay: 5e-4 # Weight decay
  scheduler:
    type: multi-step # Name of learning rate scheduler, Available: multi-step, cosine
    milestones: "20,40" # Learning rate milestones
    gamma: 0.1 # Learning rate decay factor
  start_from_scratch: True
  # set the path of at most one of the three, Otherwise set None or False
  resume: "/path/to/checkpoint.pth"  # path to checkpoint to resume from
  base_net: "/path/to/base_net.pth"  # path to base net to initialize from
  pretrained_ssd: "/path/to/pretrained_ssd.pth"  # path to pretrained SSD to initialize from
  # set the path of at most one of the two, Otherwise set None or False
  freeze_base_net: True  # whether to freeze the base net
  freeze_net: False  # whether to freeze the extra layers
# testing information
test:
  batch_size: 32 # Batch size for testing

output_dir: path/to/output/directory

# Miscellaneous configuration
misc:
  device: cuda:0  # specify the GPU device to use, e.g. cuda:0 or cuda:1 .Also possible to run on cpu, use device: cpu
  checkpoint_dir: /path/to/checkpoints/ # Directory to save trained model
  log_dir: ./logs # Directory to save training logs
  log_interval: 15
  save_interval: 40